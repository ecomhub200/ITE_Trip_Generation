{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ITE Trip Generation PDF Extractor\n",
        "\n",
        "This notebook extracts trip generation data from ITE Trip Generation Manual PDFs (Volumes 3-5) and converts them to JSON format for use in the ITE Trip Generation Calculator.\n",
        "\n",
        "## Instructions:\n",
        "1. Run Cell 1 to install dependencies\n",
        "2. Run Cell 2 to upload your PDF files\n",
        "3. Run Cell 3 to extract and parse the data\n",
        "4. Download the generated JSON file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 1: Install Dependencies\n",
        "!pip install pymupdf pandas tabula-py camelot-py[cv] pdfplumber\n",
        "!apt-get install -y ghostscript python3-tk\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Dependencies installed successfully!\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 2: Upload PDF Files\n",
        "print(\"Please upload your ITE Trip Generation Manual PDF files (Volumes 3, 4, or 5)\")\n",
        "print(\"You can upload multiple files at once.\")\n",
        "print(\"\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "pdf_files = [f for f in uploaded.keys() if f.lower().endswith('.pdf')]\n",
        "print(f\"\\nUploaded {len(pdf_files)} PDF file(s): {pdf_files}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 3: ITE Data Extraction Functions\n",
        "\n",
        "class ITEDataExtractor:\n",
        "    def __init__(self):\n",
        "        self.land_use_data = {}\n",
        "        \n",
        "        # Regex patterns for ITE data extraction\n",
        "        self.patterns = {\n",
        "            # Land use code pattern: 3 digits\n",
        "            'land_use_code': r'(?:Land Use|Code)?\\s*(\\d{3})\\b',\n",
        "            \n",
        "            # Rate patterns\n",
        "            'average_rate': r'Average\\s*(?:Weekday)?\\s*(?:Vehicle)?\\s*Trip\\s*(?:Generation)?\\s*Rate[:\\s]*([\\d.]+)',\n",
        "            'weekday_rate': r'(?:Weekday|Daily)\\s*(?:Vehicle)?\\s*Trip[s]?[:\\s]*([\\d.]+)\\s*(?:per|trips)',\n",
        "            'am_peak_rate': r'(?:AM|Morning)\\s*Peak\\s*(?:Hour)?[:\\s]*([\\d.]+)',\n",
        "            'pm_peak_rate': r'(?:PM|Evening|Afternoon)\\s*Peak\\s*(?:Hour)?[:\\s]*([\\d.]+)',\n",
        "            \n",
        "            # Equation patterns\n",
        "            'linear_equation': r'T\\s*=\\s*([\\d.]+)\\s*\\(?X\\)?\\s*([+-])\\s*([\\d.]+)',\n",
        "            'log_equation': r'(?:Ln|LN|ln)\\s*\\(?T\\)?\\s*=\\s*([\\d.]+)\\s*(?:Ln|LN|ln)\\s*\\(?X\\)?\\s*([+-])\\s*([\\d.]+)',\n",
        "            \n",
        "            # R-squared\n",
        "            'r_squared': r'R[²2]\\s*=\\s*([\\d.]+)',\n",
        "            \n",
        "            # Sample size\n",
        "            'sample_size': r'(?:Number of|N|n)\\s*(?:Studies|Sites|Observations)[:\\s]*([\\d]+)',\n",
        "            \n",
        "            # Directional distribution\n",
        "            'entering': r'(?:Entering|Enter|In)[:\\s]*([\\d]+)\\s*%',\n",
        "            'exiting': r'(?:Exiting|Exit|Out)[:\\s]*([\\d]+)\\s*%',\n",
        "            \n",
        "            # Unit patterns\n",
        "            'unit_dwelling': r'(?:per|Per)\\s*(?:Dwelling\\s*Unit|DU)',\n",
        "            'unit_ksf': r'(?:per|Per)\\s*(?:1,?000|1000|K)\\s*(?:SF|Square\\s*Feet|Sq\\.?\\s*Ft)',\n",
        "            'unit_employee': r'(?:per|Per)\\s*(?:Employee|Employees)',\n",
        "            'unit_room': r'(?:per|Per)\\s*(?:Room|Rooms)',\n",
        "            'unit_student': r'(?:per|Per)\\s*(?:Student|Students)',\n",
        "            'unit_acre': r'(?:per|Per)\\s*(?:Acre|Acres)',\n",
        "            'unit_bed': r'(?:per|Per)\\s*(?:Bed|Beds)',\n",
        "            'unit_fueling': r'(?:per|Per)\\s*(?:Fueling\\s*Position|VFP)',\n",
        "            'unit_screen': r'(?:per|Per)\\s*(?:Screen|Screens)',\n",
        "            'unit_lane': r'(?:per|Per)\\s*(?:Lane|Lanes)',\n",
        "            'unit_hole': r'(?:per|Per)\\s*(?:Hole|Holes)',\n",
        "        }\n",
        "        \n",
        "        # Known ITE land use names (11th Edition)\n",
        "        self.land_use_names = {\n",
        "            '110': 'General Light Industrial',\n",
        "            '130': 'Industrial Park',\n",
        "            '140': 'Manufacturing',\n",
        "            '150': 'Warehousing',\n",
        "            '151': 'Mini-Warehouse',\n",
        "            '210': 'Single-Family Detached Housing',\n",
        "            '215': 'Single-Family Attached Housing',\n",
        "            '220': 'Multifamily Housing (Low-Rise)',\n",
        "            '221': 'Multifamily Housing (Mid-Rise)',\n",
        "            '222': 'Multifamily Housing (High-Rise)',\n",
        "            '230': 'Residential Condominium/Townhouse',\n",
        "            '240': 'Mobile Home Park',\n",
        "            '251': 'Senior Adult Housing - Detached',\n",
        "            '252': 'Senior Adult Housing - Attached',\n",
        "            '253': 'Congregate Care Facility',\n",
        "            '254': 'Assisted Living',\n",
        "            '255': 'Continuing Care Retirement Community',\n",
        "            '260': 'Recreational Homes',\n",
        "            '270': 'Residential Planned Unit Development',\n",
        "            '310': 'Hotel',\n",
        "            '311': 'All Suites Hotel',\n",
        "            '312': 'Business Hotel',\n",
        "            '320': 'Motel',\n",
        "            '330': 'Resort Hotel',\n",
        "            '411': 'Public Park',\n",
        "            '420': 'Marina',\n",
        "            '430': 'Golf Course',\n",
        "            '444': 'Movie Theater',\n",
        "            '445': 'Multiplex Movie Theater',\n",
        "            '480': 'Amusement Park',\n",
        "            '491': 'Racquet/Tennis Club',\n",
        "            '492': 'Health/Fitness Club',\n",
        "            '495': 'Recreational Community Center',\n",
        "            '520': 'Elementary School',\n",
        "            '522': 'Middle School/Junior High School',\n",
        "            '530': 'High School',\n",
        "            '534': 'Private School (K-8)',\n",
        "            '536': 'Private School (K-12)',\n",
        "            '540': 'Junior/Community College',\n",
        "            '550': 'University/College',\n",
        "            '560': 'Church',\n",
        "            '565': 'Day Care Center',\n",
        "            '566': 'Cemetery',\n",
        "            '575': 'Fire and Rescue Station',\n",
        "            '590': 'Library',\n",
        "            '610': 'Hospital',\n",
        "            '620': 'Nursing Home',\n",
        "            '630': 'Clinic',\n",
        "            '640': 'Animal Hospital/Veterinary Clinic',\n",
        "            '710': 'General Office Building',\n",
        "            '714': 'Corporate Headquarters Building',\n",
        "            '715': 'Single Tenant Office Building',\n",
        "            '720': 'Medical-Dental Office Building',\n",
        "            '730': 'Government Office Building',\n",
        "            '750': 'Office Park',\n",
        "            '760': 'Research and Development Center',\n",
        "            '770': 'Business Park',\n",
        "            '812': 'Building Materials and Lumber Store',\n",
        "            '813': 'Free-Standing Discount Superstore',\n",
        "            '814': 'Variety Store',\n",
        "            '815': 'Free-Standing Discount Store',\n",
        "            '816': 'Hardware/Paint Store',\n",
        "            '817': 'Nursery (Garden Center)',\n",
        "            '820': 'Shopping Center',\n",
        "            '821': 'Shopping Plaza (40-150k)',\n",
        "            '822': 'Strip Retail Plaza (<40k)',\n",
        "            '840': 'Automobile Sales (New)',\n",
        "            '841': 'Automobile Sales (Used)',\n",
        "            '848': 'Tire Store',\n",
        "            '850': 'Supermarket',\n",
        "            '851': 'Convenience Market',\n",
        "            '857': 'Discount Club',\n",
        "            '860': 'Wholesale Market',\n",
        "            '861': 'Sporting Goods Superstore',\n",
        "            '862': 'Home Improvement Superstore',\n",
        "            '863': 'Electronics Superstore',\n",
        "            '866': 'Pet Supply Superstore',\n",
        "            '867': 'Office Supply Superstore',\n",
        "            '875': 'Department Store',\n",
        "            '879': 'Arts and Crafts Store',\n",
        "            '880': 'Pharmacy/Drugstore without Drive-Through',\n",
        "            '881': 'Pharmacy/Drugstore with Drive-Through',\n",
        "            '890': 'Furniture Store',\n",
        "            '911': 'Walk-in Bank',\n",
        "            '912': 'Drive-in Bank',\n",
        "            '930': 'Fast Casual Restaurant',\n",
        "            '931': 'Quality Restaurant',\n",
        "            '932': 'High-Turnover (Sit-Down) Restaurant',\n",
        "            '933': 'Fast Food Restaurant without Drive-Through',\n",
        "            '934': 'Fast Food Restaurant with Drive-Through',\n",
        "            '936': 'Coffee/Donut Shop without Drive-Through',\n",
        "            '937': 'Coffee/Donut Shop with Drive-Through',\n",
        "            '938': 'Coffee/Donut Shop with Drive-Through Only',\n",
        "            '941': 'Quick Lubrication Vehicle Shop',\n",
        "            '942': 'Automobile Care Center',\n",
        "            '944': 'Gasoline/Service Station',\n",
        "            '945': 'Gasoline/Service Station with Convenience Market',\n",
        "            '947': 'Self-Service Car Wash',\n",
        "            '948': 'Automated Car Wash',\n",
        "        }\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract all text from PDF with page markers.\"\"\"\n",
        "        doc = fitz.open(pdf_path)\n",
        "        pages_text = []\n",
        "        for page_num in range(doc.page_count):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text()\n",
        "            pages_text.append({\n",
        "                'page': page_num + 1,\n",
        "                'text': text\n",
        "            })\n",
        "        doc.close()\n",
        "        return pages_text\n",
        "\n",
        "    def detect_unit(self, text):\n",
        "        \"\"\"Detect the unit of measurement from text.\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        if 'dwelling' in text_lower or ' du' in text_lower:\n",
        "            return 'Dwelling Units'\n",
        "        elif '1000' in text_lower or '1,000' in text_lower or 'ksf' in text_lower:\n",
        "            if 'gla' in text_lower:\n",
        "                return '1000 SF GLA'\n",
        "            return '1000 SF GFA'\n",
        "        elif 'employee' in text_lower:\n",
        "            return 'Employees'\n",
        "        elif 'room' in text_lower:\n",
        "            return 'Rooms'\n",
        "        elif 'student' in text_lower:\n",
        "            return 'Students'\n",
        "        elif 'acre' in text_lower:\n",
        "            return 'Acres'\n",
        "        elif 'bed' in text_lower:\n",
        "            return 'Beds'\n",
        "        elif 'fueling' in text_lower or 'vfp' in text_lower:\n",
        "            return 'Fueling Positions'\n",
        "        elif 'screen' in text_lower:\n",
        "            return 'Screens'\n",
        "        elif 'lane' in text_lower:\n",
        "            return 'Lanes'\n",
        "        elif 'hole' in text_lower:\n",
        "            return 'Holes'\n",
        "        elif 'seat' in text_lower:\n",
        "            return 'Seats'\n",
        "        elif 'service bay' in text_lower:\n",
        "            return 'Service Bays'\n",
        "        return '1000 SF GFA'  # Default\n",
        "\n",
        "    def parse_equation(self, text):\n",
        "        \"\"\"Parse fitted curve equation from text.\"\"\"\n",
        "        # Try linear equation first: T = aX + b or T = aX - b\n",
        "        linear_match = re.search(r'T\\s*=\\s*([\\d.]+)\\s*\\(?X\\)?\\s*([+-])\\s*([\\d.]+)', text, re.IGNORECASE)\n",
        "        if linear_match:\n",
        "            a = float(linear_match.group(1))\n",
        "            sign = 1 if linear_match.group(2) == '+' else -1\n",
        "            b = float(linear_match.group(3)) * sign\n",
        "            return {'type': 'linear', 'a': a, 'b': b}\n",
        "        \n",
        "        # Try log equation: Ln(T) = a*Ln(X) + b\n",
        "        log_match = re.search(r'(?:Ln|LN|ln)\\s*\\(?T\\)?\\s*=\\s*([\\d.]+)\\s*(?:Ln|LN|ln)\\s*\\(?X\\)?\\s*([+-])\\s*([\\d.]+)', text, re.IGNORECASE)\n",
        "        if log_match:\n",
        "            a = float(log_match.group(1))\n",
        "            sign = 1 if log_match.group(2) == '+' else -1\n",
        "            b = float(log_match.group(3)) * sign\n",
        "            return {'type': 'log', 'a': a, 'b': b}\n",
        "        \n",
        "        return None\n",
        "\n",
        "    def extract_land_use_data(self, pages_text):\n",
        "        \"\"\"Extract land use data from pages.\"\"\"\n",
        "        extracted_data = {}\n",
        "        \n",
        "        for page_data in pages_text:\n",
        "            text = page_data['text']\n",
        "            page_num = page_data['page']\n",
        "            \n",
        "            # Find land use codes in this page\n",
        "            code_matches = re.findall(r'\\b(\\d{3})\\b', text)\n",
        "            \n",
        "            for code in code_matches:\n",
        "                # Skip if not a valid ITE code range\n",
        "                code_int = int(code)\n",
        "                if code_int < 100 or code_int > 999:\n",
        "                    continue\n",
        "                    \n",
        "                # Check if this looks like a land use code page\n",
        "                if code in self.land_use_names or any(keyword in text.lower() for keyword in ['trip generation', 'average rate', 'fitted curve']):\n",
        "                    \n",
        "                    if code not in extracted_data:\n",
        "                        extracted_data[code] = {\n",
        "                            'code': code,\n",
        "                            'name': self.land_use_names.get(code, f'Land Use {code}'),\n",
        "                            'pages_found': [],\n",
        "                            'raw_text_samples': [],\n",
        "                            'weekday': {},\n",
        "                            'am_peak': {},\n",
        "                            'pm_peak': {},\n",
        "                        }\n",
        "                    \n",
        "                    extracted_data[code]['pages_found'].append(page_num)\n",
        "                    \n",
        "                    # Extract rates\n",
        "                    rate_patterns = [\n",
        "                        (r'(?:Average|Avg\\.?)\\s*(?:Rate|Trip)[:\\s]*([\\d.]+)', 'rate'),\n",
        "                        (r'([\\d.]+)\\s*(?:trips?|vehicle)', 'rate'),\n",
        "                    ]\n",
        "                    \n",
        "                    for pattern, field in rate_patterns:\n",
        "                        match = re.search(pattern, text, re.IGNORECASE)\n",
        "                        if match:\n",
        "                            try:\n",
        "                                rate = float(match.group(1))\n",
        "                                if 0 < rate < 10000:  # Sanity check\n",
        "                                    if 'weekday' in text.lower() or 'daily' in text.lower():\n",
        "                                        extracted_data[code]['weekday']['rate'] = rate\n",
        "                                    elif 'am' in text.lower() and 'peak' in text.lower():\n",
        "                                        extracted_data[code]['am_peak']['rate'] = rate\n",
        "                                    elif 'pm' in text.lower() and 'peak' in text.lower():\n",
        "                                        extracted_data[code]['pm_peak']['rate'] = rate\n",
        "                            except ValueError:\n",
        "                                pass\n",
        "                    \n",
        "                    # Extract R-squared\n",
        "                    r2_match = re.search(r'R[²2]\\s*[=:]?\\s*([\\d.]+)', text)\n",
        "                    if r2_match:\n",
        "                        try:\n",
        "                            r2 = float(r2_match.group(1))\n",
        "                            if 0 <= r2 <= 1:\n",
        "                                if 'weekday' in text.lower():\n",
        "                                    extracted_data[code]['weekday']['r_squared'] = r2\n",
        "                        except ValueError:\n",
        "                            pass\n",
        "                    \n",
        "                    # Extract sample size\n",
        "                    sample_match = re.search(r'(?:Number of|N|n)\\s*(?:Studies|Sites)[:\\s]*(\\d+)', text, re.IGNORECASE)\n",
        "                    if sample_match:\n",
        "                        extracted_data[code]['weekday']['sample_size'] = int(sample_match.group(1))\n",
        "                    \n",
        "                    # Extract directional split\n",
        "                    enter_match = re.search(r'(\\d+)\\s*%?\\s*(?:entering|enter|in)', text, re.IGNORECASE)\n",
        "                    exit_match = re.search(r'(\\d+)\\s*%?\\s*(?:exiting|exit|out)', text, re.IGNORECASE)\n",
        "                    if enter_match and exit_match:\n",
        "                        entering = int(enter_match.group(1))\n",
        "                        exiting = int(exit_match.group(1))\n",
        "                        if entering + exiting == 100:\n",
        "                            extracted_data[code]['am_peak']['entering'] = entering\n",
        "                            extracted_data[code]['am_peak']['exiting'] = exiting\n",
        "                            extracted_data[code]['pm_peak']['entering'] = exiting  # Typically reversed\n",
        "                            extracted_data[code]['pm_peak']['exiting'] = entering\n",
        "                    \n",
        "                    # Extract equation\n",
        "                    equation = self.parse_equation(text)\n",
        "                    if equation:\n",
        "                        extracted_data[code]['weekday']['equation'] = equation\n",
        "                    \n",
        "                    # Detect unit\n",
        "                    extracted_data[code]['unit'] = self.detect_unit(text)\n",
        "                    \n",
        "                    # Store sample of raw text for debugging\n",
        "                    if len(extracted_data[code]['raw_text_samples']) < 3:\n",
        "                        extracted_data[code]['raw_text_samples'].append(text[:500])\n",
        "        \n",
        "        return extracted_data\n",
        "\n",
        "    def format_for_database(self, extracted_data):\n",
        "        \"\"\"Format extracted data to match ite-database.js structure.\"\"\"\n",
        "        formatted = {}\n",
        "        \n",
        "        for code, data in extracted_data.items():\n",
        "            # Determine category\n",
        "            code_int = int(code)\n",
        "            if code_int < 100:\n",
        "                category = 'Port, Freight, Terminal'\n",
        "            elif code_int < 200:\n",
        "                category = 'Industrial'\n",
        "            elif code_int < 300:\n",
        "                category = 'Residential'\n",
        "            elif code_int < 400:\n",
        "                category = 'Lodging'\n",
        "            elif code_int < 500:\n",
        "                category = 'Recreational'\n",
        "            elif code_int < 600:\n",
        "                category = 'Institutional'\n",
        "            elif code_int < 700:\n",
        "                category = 'Medical'\n",
        "            elif code_int < 800:\n",
        "                category = 'Office'\n",
        "            elif code_int < 900:\n",
        "                category = 'Retail'\n",
        "            else:\n",
        "                category = 'Services'\n",
        "            \n",
        "            formatted[code] = {\n",
        "                'code': code,\n",
        "                'name': data.get('name', f'Land Use {code}'),\n",
        "                'category': category,\n",
        "                'unit': data.get('unit', '1000 SF GFA'),\n",
        "                'weekday': {\n",
        "                    'rate': data.get('weekday', {}).get('rate'),\n",
        "                    'equation': data.get('weekday', {}).get('equation'),\n",
        "                    'r_squared': data.get('weekday', {}).get('r_squared'),\n",
        "                    'sample_size': data.get('weekday', {}).get('sample_size')\n",
        "                },\n",
        "                'am_peak': {\n",
        "                    'rate': data.get('am_peak', {}).get('rate'),\n",
        "                    'equation': data.get('am_peak', {}).get('equation'),\n",
        "                    'r_squared': data.get('am_peak', {}).get('r_squared'),\n",
        "                    'entering': data.get('am_peak', {}).get('entering'),\n",
        "                    'exiting': data.get('am_peak', {}).get('exiting')\n",
        "                },\n",
        "                'pm_peak': {\n",
        "                    'rate': data.get('pm_peak', {}).get('rate'),\n",
        "                    'equation': data.get('pm_peak', {}).get('equation'),\n",
        "                    'r_squared': data.get('pm_peak', {}).get('r_squared'),\n",
        "                    'entering': data.get('pm_peak', {}).get('entering'),\n",
        "                    'exiting': data.get('pm_peak', {}).get('exiting')\n",
        "                },\n",
        "                'source': 'ITE 11th Edition',\n",
        "                'pages_found': data.get('pages_found', [])\n",
        "            }\n",
        "        \n",
        "        return formatted\n",
        "\n",
        "print(\"ITEDataExtractor class loaded successfully!\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 4: Process PDFs and Extract Data\n",
        "\n",
        "extractor = ITEDataExtractor()\n",
        "all_extracted_data = {}\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    print(f\"\\nProcessing: {pdf_file}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Extract text from PDF\n",
        "    pages_text = extractor.extract_text_from_pdf(pdf_file)\n",
        "    print(f\"  Extracted text from {len(pages_text)} pages\")\n",
        "    \n",
        "    # Extract land use data\n",
        "    extracted = extractor.extract_land_use_data(pages_text)\n",
        "    print(f\"  Found {len(extracted)} potential land use codes\")\n",
        "    \n",
        "    # Merge with existing data\n",
        "    for code, data in extracted.items():\n",
        "        if code not in all_extracted_data:\n",
        "            all_extracted_data[code] = data\n",
        "        else:\n",
        "            # Merge data from multiple PDFs\n",
        "            for key in ['weekday', 'am_peak', 'pm_peak']:\n",
        "                for field, value in data.get(key, {}).items():\n",
        "                    if value is not None and all_extracted_data[code].get(key, {}).get(field) is None:\n",
        "                        if key not in all_extracted_data[code]:\n",
        "                            all_extracted_data[code][key] = {}\n",
        "                        all_extracted_data[code][key][field] = value\n",
        "\n",
        "print(f\"\\n\\nTotal unique land use codes found: {len(all_extracted_data)}\")\n",
        "print(\"\\nCodes found:\")\n",
        "for code in sorted(all_extracted_data.keys()):\n",
        "    name = all_extracted_data[code].get('name', 'Unknown')\n",
        "    pages = all_extracted_data[code].get('pages_found', [])\n",
        "    print(f\"  {code}: {name} (pages: {pages[:5]}{'...' if len(pages) > 5 else ''})\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 5: Format and Export Data\n",
        "\n",
        "# Format for database\n",
        "formatted_data = extractor.format_for_database(all_extracted_data)\n",
        "\n",
        "# Create output structure\n",
        "output = {\n",
        "    'metadata': {\n",
        "        'source': 'ITE Trip Generation Manual, 11th Edition',\n",
        "        'extracted_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
        "        'total_codes': len(formatted_data),\n",
        "        'files_processed': pdf_files\n",
        "    },\n",
        "    'land_use_codes': formatted_data\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "output_filename = 'ite_extracted_data.json'\n",
        "with open(output_filename, 'w') as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(f\"Data saved to {output_filename}\")\n",
        "print(f\"\\nTotal codes extracted: {len(formatted_data)}\")\n",
        "\n",
        "# Show sample of extracted data\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SAMPLE EXTRACTED DATA:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "sample_codes = ['210', '710', '820', '934']  # Common codes to show\n",
        "for code in sample_codes:\n",
        "    if code in formatted_data:\n",
        "        print(f\"\\n{code}: {formatted_data[code]['name']}\")\n",
        "        print(f\"  Unit: {formatted_data[code]['unit']}\")\n",
        "        print(f\"  Weekday Rate: {formatted_data[code]['weekday'].get('rate', 'Not found')}\")\n",
        "        print(f\"  AM Peak Rate: {formatted_data[code]['am_peak'].get('rate', 'Not found')}\")\n",
        "        print(f\"  PM Peak Rate: {formatted_data[code]['pm_peak'].get('rate', 'Not found')}\")\n",
        "        print(f\"  R²: {formatted_data[code]['weekday'].get('r_squared', 'Not found')}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 6: Generate JavaScript Database Code\n",
        "\n",
        "def generate_js_database(formatted_data):\n",
        "    \"\"\"Generate JavaScript code for ite-database.js\"\"\"\n",
        "    js_code = \"\"\"/**\n",
        " * ITE Trip Generation Database\n",
        " * Extracted from ITE Trip Generation Manual, 11th Edition\n",
        " * Auto-generated on \"\"\" + pd.Timestamp.now().strftime('%Y-%m-%d') + \"\"\"\n",
        " */\n",
        "\n",
        "const ITE_DATABASE = {\n",
        "\"\"\"\n",
        "    \n",
        "    for code in sorted(formatted_data.keys()):\n",
        "        data = formatted_data[code]\n",
        "        \n",
        "        # Build weekday object\n",
        "        weekday_parts = []\n",
        "        if data['weekday'].get('rate') is not None:\n",
        "            weekday_parts.append(f\"rate: {data['weekday']['rate']}\")\n",
        "        else:\n",
        "            weekday_parts.append(\"rate: null\")\n",
        "        \n",
        "        if data['weekday'].get('equation'):\n",
        "            eq = data['weekday']['equation']\n",
        "            weekday_parts.append(f'equation: {{ type: \"{eq[\"type\"]}\", a: {eq[\"a\"]}, b: {eq[\"b\"]} }}')\n",
        "        else:\n",
        "            weekday_parts.append(\"equation: null\")\n",
        "        \n",
        "        if data['weekday'].get('r_squared') is not None:\n",
        "            weekday_parts.append(f\"r_squared: {data['weekday']['r_squared']}\")\n",
        "        else:\n",
        "            weekday_parts.append(\"r_squared: null\")\n",
        "        \n",
        "        if data['weekday'].get('sample_size') is not None:\n",
        "            weekday_parts.append(f\"sample_size: {data['weekday']['sample_size']}\")\n",
        "        \n",
        "        # Build AM peak object\n",
        "        am_parts = []\n",
        "        if data['am_peak'].get('rate') is not None:\n",
        "            am_parts.append(f\"rate: {data['am_peak']['rate']}\")\n",
        "        else:\n",
        "            am_parts.append(\"rate: null\")\n",
        "        am_parts.append(\"equation: null\")\n",
        "        am_parts.append(\"r_squared: null\")\n",
        "        if data['am_peak'].get('entering') is not None:\n",
        "            am_parts.append(f\"entering: {data['am_peak']['entering']}\")\n",
        "            am_parts.append(f\"exiting: {data['am_peak']['exiting']}\")\n",
        "        \n",
        "        # Build PM peak object\n",
        "        pm_parts = []\n",
        "        if data['pm_peak'].get('rate') is not None:\n",
        "            pm_parts.append(f\"rate: {data['pm_peak']['rate']}\")\n",
        "        else:\n",
        "            pm_parts.append(\"rate: null\")\n",
        "        pm_parts.append(\"equation: null\")\n",
        "        pm_parts.append(\"r_squared: null\")\n",
        "        if data['pm_peak'].get('entering') is not None:\n",
        "            pm_parts.append(f\"entering: {data['pm_peak']['entering']}\")\n",
        "            pm_parts.append(f\"exiting: {data['pm_peak']['exiting']}\")\n",
        "        \n",
        "        js_code += f'''  \"{code}\": {{\n",
        "    code: \"{code}\",\n",
        "    name: \"{data['name']}\",\n",
        "    category: \"{data['category']}\",\n",
        "    unit: \"{data['unit']}\",\n",
        "    weekday: {{\n",
        "      {', '.join(weekday_parts)}\n",
        "    }},\n",
        "    am_peak: {{\n",
        "      {', '.join(am_parts)}\n",
        "    }},\n",
        "    pm_peak: {{\n",
        "      {', '.join(pm_parts)}\n",
        "    }},\n",
        "    source: \"ITE 11th Edition\"\n",
        "  }},\n",
        "'''\n",
        "    \n",
        "    js_code += \"};\"\n",
        "    return js_code\n",
        "\n",
        "# Generate JS code\n",
        "js_code = generate_js_database(formatted_data)\n",
        "\n",
        "# Save to file\n",
        "js_filename = 'ite_database_extracted.js'\n",
        "with open(js_filename, 'w') as f:\n",
        "    f.write(js_code)\n",
        "\n",
        "print(f\"JavaScript database code saved to {js_filename}\")\n",
        "print(f\"\\nFirst 2000 characters of generated code:\")\n",
        "print(\"=\"*50)\n",
        "print(js_code[:2000])"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 7: Download Generated Files\n",
        "\n",
        "print(\"Downloading generated files...\")\n",
        "print(\"\")\n",
        "\n",
        "# Download JSON\n",
        "files.download('ite_extracted_data.json')\n",
        "print(\"1. ite_extracted_data.json - Complete extracted data in JSON format\")\n",
        "\n",
        "# Download JS\n",
        "files.download('ite_database_extracted.js')\n",
        "print(\"2. ite_database_extracted.js - Ready-to-use JavaScript database code\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"NEXT STEPS:\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. Review the extracted data for accuracy\")\n",
        "print(\"2. Compare with official ITE values if available\")\n",
        "print(\"3. Merge with existing ite-database.js in your project\")\n",
        "print(\"4. Update the 'source' field if using 12th Edition rates\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If the extraction doesn't capture all data correctly, you can:\n",
        "\n",
        "1. **View raw extracted text** to understand the PDF structure:\n",
        "```python\n",
        "# Show raw text from specific pages\n",
        "for page in pages_text[0:10]:  # First 10 pages\n",
        "    print(f\"Page {page['page']}:\")\n",
        "    print(page['text'][:1000])\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "```\n",
        "\n",
        "2. **Search for specific land use codes**:\n",
        "```python\n",
        "target_code = '210'\n",
        "for page in pages_text:\n",
        "    if target_code in page['text']:\n",
        "        print(f\"Found {target_code} on page {page['page']}\")\n",
        "        print(page['text'][:2000])\n",
        "```\n",
        "\n",
        "3. **Manually add missing data** to the JSON file before downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Cell 8: Debug - View Raw Text for Specific Pages (Optional)\n",
        "\n",
        "# Uncomment and modify to debug specific pages\n",
        "\n",
        "# target_code = '210'  # Change this to the code you want to find\n",
        "# \n",
        "# print(f\"Searching for Land Use Code {target_code}...\")\n",
        "# print(\"=\"*50)\n",
        "# \n",
        "# for pdf_file in pdf_files:\n",
        "#     pages = extractor.extract_text_from_pdf(pdf_file)\n",
        "#     for page in pages:\n",
        "#         if target_code in page['text']:\n",
        "#             print(f\"\\nFound in {pdf_file}, Page {page['page']}:\")\n",
        "#             print(\"-\"*50)\n",
        "#             print(page['text'][:3000])\n",
        "#             print(\"\\n\")"
      ],
      "outputs": []
    }
  ]
}
